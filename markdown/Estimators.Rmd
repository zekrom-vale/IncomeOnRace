### Detect Autocorrelation
Autocorrelation is a major issue in time series as it breaks the independent observations that OLS (Ordinary Least Squares) expects.  So, autocorrelation must be removed before fitting the model.  This can be resolved by adding lags to the regression.
```{r}
WagesAll=Wages%>%
	filter(is.na(Race),is.na(Gender))%>%
	# Convert Year into date
	mutate(Date=lubridate::as_date(glue("{Date}-1-1")))%>%
	select(Date, Median)
WagesAll%>%
	plot_acf_diagnostics(
		.value=Median,
		.date_var = Date,
		.interactive = !(isKnit()&&knitr::is_latex_output()),
		# Use years as the lag interval so it's not confusing.
		.lags=glue("{max(Wages$Date)-min(Wages$Date)} years")
)
```
<small>Lags in years</small>

```{r}
mod0=dynlm(Median~Date, data = Wages)

bgtest(mod0, order = 1, type = "F", fill = NA)
```

As you can see there is a lot of autocorrelation as indicated by the ACF graph and agreed by the `bgtest`, the larger the value the more correlated the data is to the previous value. To fix it we update the models to include a lag of the dependent variable.  According to the PACF, it appears that there is only one lag that is required to fix the issue.  $+\beta Median_{t-x} \forall x\in\mathbb{Z}$

These models now become:
$$mod0 : Median_t=\beta_3Date+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$mod1 : Median=\beta_3Date+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$mod2 : \log(Median)=\beta_3Date+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$modWhite : \log(Median)=\beta_3Date*White+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$modBlack : \log(Median)=\beta_3Date*Black+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$modBlack : \log(Median)=\beta_3Date*Hispanic+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
<small>Where $White$, $Black$, and $Hispanic$ are binary features based on $Race$.</small>

```{r}
g=Wages%>%
	filter(is.na(Gender))%>%
	ggplot(aes(x=Date, y=log(Median), col=Race))+
	geom_line()+
	geom_smooth(
		method = lm,
		se=F
	)+
	ggtitle("Models for Median Income vs Time per Race")+
	xlab("Year")+
	ylab("Log of Median Income")
ggdisp(g)
```
<small>Does not incorporate lags into the visualization</small>


```{r}
mod1=lm(
	Median~Date
	+stats::lag(Median, -1)
	+stats::lag(Median, -2),
	data = Wages
)
mod2=lm(
	log(Median)~Date
	+stats::lag(Median, -1)
	+stats::lag(Median, -2),
	data = Wages
)
```

### Model Accuracy

```{r}
WageSplit=initial_time_split(Wages, lag = 2)

mod1t=lm(
	Median~Date
	+stats::lag(Median, -1)
	+stats::lag(Median, -2),
	data = training(WageSplit)
)
mod2t=lm(
	log(Median)~Date
	+stats::lag(Median, -1)
	+stats::lag(Median, -2),
	data = training(WageSplit)
)
```

```{r, warning=FALSE}
t=testing(WageSplit)
m1=mod1t%>%
	predict(t)%>%
	tibble(.pred=.)%>%
	bind_cols(t)%>%
	rmse(truth=Median, estimate=.pred)%>%
	mutate(mod="mod1")
m2=mod2t%>%
	predict(t)%>%
	tibble(.pred=.)%>%
	bind_cols(t)%>%
	rmse(truth=Median, estimate=.pred)%>%
	mutate(mod="mod2")
m1%>%
	union(m2)%>%
	dplyr::select(mod, .metric, .estimator, .estimate)%>%
	disp()
```
According to the testing data, `mod1` is the best model at predicting as it has a lower `RMSE`.

```{r}
plot.fitted(mod1, "Residuals vs. Fits mod1 (Dependent Variable: {name})", fun=ylim(c(-1e-14, 1e-14)))%>%
	ggdisp()
```

```{r}
plot.fitted(mod2, "Residuals vs. Fits mod2 (Dependent Variable: ")%>%
	ggdisp()
```
Even the Residuals vs Fitted graph agrees with `RMSE` as most of the data is gathered around 0 in the gray aria and spread out.  Where `mod2` shows a curve going outside that aria.  So the models will be based on `mod1`.

$$modWhite : Median=\beta_3Date*White+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$modBlack : Median=\beta_3Date*Black+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$
$$modBlack : Median=\beta_3Date*Hispanic+\beta_2Median_{t-2}+\beta_1Median_{t-1}+\beta_0+e$$

So, the updated model looks like this:
```{r}
g=Wages%>%
	filter(is.na(Gender))%>%
	ggplot(aes(x=Date, y=Median, col=Race))+
	geom_line()+
	geom_smooth(
		method = lm,
		se=F
	)+
	ggtitle("Models for Median Income vs Time per Race")+
	xlab("Year")+
	ylab("Median Income")
ggdisp(g)
```

### Chow Test
```{r, results='asis'}
chow=function(racestr){
	WagesRace=Wages%>%
		mutate(R=if_else(Race==racestr, 1, 0))%>%
		filter(!is.na(Race),is.na(Gender))
	
	mod2=lm(Median~Date
					+stats::lag(Median, -1)
					+stats::lag(Median, -2),
					data=WagesRace
	)
	
	
	modRace=lm(Median~Date*R
						 +stats::lag(Median, -1)
						 +stats::lag(Median, -2),
					data=WagesRace
	)
	
	stargazer(mod2, modRace,
		header=FALSE,
		type=knittype,
	  title="Model comparison, 'wage' equation",
	  keep.stat="n",digits=2, single.row=TRUE,
	  intercept.bottom=FALSE
	)
	
	anova(mod2, modRace)%>%
		kable()
}
chow("white")
```
After performing a chow test we can reject our null hypothesis that there is no significant difference between the median income of individuals aged 16 and older in the United States and the median income of white individuals who are 16 and older in the United States, since our p-value is less than 0.01. We conclude that the median income of white individuals aged 16 and older in the United States is significantly higher than the median income of individuals aged 16 and older.

<!--As the `p-value` is zero there is no chance that the `Median` wage is comparable between white people and non-white people.  So we cannot ignore `Race` as if fails the chow test telling us we have to accept the alternative hypothesis ($H_A$).  This is that white individuals make a significantly different amount of money compared to non-whites.-->


```{r, results='asis'}
chow("black")
```

After performing another chow test we can reject our null hypothesis that there is no significant difference between the median income of individuals aged 16 and older in the United States and the median income of black individuals who are 16 and older in the United States, since our p-value is less than 0.01. We conclude that the median income of black individuals aged 16 and older in the United States is significantly lower than the median income of individuals aged 16 and older.

```{r, results='asis'}
chow("hispanic")
```

After performing a chow test we can reject our null hypothesis that there is no significant difference between the median income of individuals aged 16 and older in the United States and the median income of hispanic individuals who are 16 and older in the United States, since our p-value is less than 0.01. We conclude that the median income of white individuals aged 16 and older in the United States is significantly higher than the median income of individuals aged 16 and older.

<!--After performing our final chow test, we can reject our null hypothesis that there is no significant difference between the median income of individuals aged 16 and older in the United States and the median income.-->

Some limitations to the experiment are the data collection. This is because we are unable to collect everyoneâ€™s income in the united states to test this. However, the data we do have gives a good representation of the income of people as we currently know it in the United States. Another major issue would be the voluntary data used. People who volunteer to give out this data may not participate due to their current financial status. This would skew the data and ultimately change the outcome. 